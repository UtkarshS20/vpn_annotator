{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_22208\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     CLNT_RMT_IP  ROI_CLICK_EVENT_TS  \\\n",
      "0   1  77.111.247.168 2020-08-02 18:37:01   \n",
      "1   2   66.249.73.101 2020-08-21 03:36:38   \n",
      "2   3  77.111.247.129 2020-08-21 03:36:38   \n",
      "3   4   66.249.73.101 2020-08-21 03:36:33   \n",
      "4   5  77.111.247.129 2020-08-21 03:36:33   \n",
      "\n",
      "                                          BRWSR_NAME  ams_trans_rsn_cd  \\\n",
      "0  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "1  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "2  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "3  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "4  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "\n",
      "  ams_pblshr_id    buyer_id  is_vpn            click_id  \n",
      "0    5574672411   valen_949       1  209245484389035777  \n",
      "1    5574672411  morbanisaf       1  209453736892211586  \n",
      "2    5574672411  morbanisaf       1  209453736892211586  \n",
      "3    5574672411  morbanisaf       1  209453736892211586  \n",
      "4    5574672411  morbanisaf       1  209453736892211586  \n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import mysql.connector\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "# from scripts.db_utils import create_ebay_connection\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def create_ebay_connection():\n",
    "    \"\"\"Create connection to the hosted SQL Server database for IP addresses.\"\"\"\n",
    "    try:\n",
    "        connection = pyodbc.connect(\n",
    "            f\"DRIVER={{MySQL ODBC 9.1 Unicode Driver}};\"\n",
    "            f\"SERVER={os.getenv('EBAY_DB_HOST')};\"\n",
    "            f\"DATABASE={os.getenv('EBAY_DB_NAME')};\"\n",
    "            f\"UID={os.getenv('EBAY_DB_USER')};\"\n",
    "            f\"PWD={os.getenv('EBAY_DB_PASSWORD')}\"\n",
    "        )\n",
    "        return connection\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error connecting to hosted database: {e}\")\n",
    "        return None\n",
    "# Database connection parameters\n",
    "conn = create_ebay_connection()\n",
    "\n",
    "query = \"SELECT * FROM tbl_iptrace_user_activity where ams_trans_rsn_cd=0\"\n",
    "\n",
    "\n",
    "def fetch_data_in_chunks(conn, query, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Fetch data from the database in chunks, then convert to Dask DataFrame.\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    while True:\n",
    "        # Modify the query to include pagination using LIMIT and OFFSET for chunks\n",
    "        paginated_query = f\"{query} LIMIT {chunk_size} OFFSET {offset}\"\n",
    "        \n",
    "        # Fetch data in chunks using pandas (it handles column and row alignment internally)\n",
    "        df_chunk = pd.read_sql_query(paginated_query, conn)\n",
    "        \n",
    "        if df_chunk.empty:\n",
    "            break\n",
    "        \n",
    "        # Convert to Dask DataFrame\n",
    "        dask_df = dd.from_pandas(df_chunk, npartitions=4)\n",
    "        \n",
    "        yield dask_df\n",
    "        \n",
    "        offset += chunk_size\n",
    "\n",
    "\n",
    "dask_chunks = []\n",
    "\n",
    "# Fetch chunks and store them in the list\n",
    "for dask_df_chunk in fetch_data_in_chunks(conn, query, chunk_size=100000):\n",
    "    dask_chunks.append(dask_df_chunk)\n",
    "\n",
    "# Concatenate all chunks into a single Dask DataFrame\n",
    "full_dask_df = dd.concat(dask_chunks)\n",
    "\n",
    "\n",
    "# Show the result\n",
    "print(full_dask_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLNT_RMT_IP</th>\n",
       "      <th>ROI_CLICK_EVENT_TS</th>\n",
       "      <th>BRWSR_NAME</th>\n",
       "      <th>ams_pblshr_id</th>\n",
       "      <th>buyer_id</th>\n",
       "      <th>click_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54238</th>\n",
       "      <td>172.226.114.69</td>\n",
       "      <td>2024-09-05 11:04:49</td>\n",
       "      <td>ebayUserAgent/eBayIOS;6.174.0;iOS;17.6.1;Apple...</td>\n",
       "      <td>5575612316</td>\n",
       "      <td>srw38</td>\n",
       "      <td>226172465646404352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54239</th>\n",
       "      <td>208.115.224.233</td>\n",
       "      <td>2024-09-29 06:41:18</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>5575532731</td>\n",
       "      <td>katzenklo_16</td>\n",
       "      <td>226442175813927936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54240</th>\n",
       "      <td>138.199.29.213</td>\n",
       "      <td>2024-10-09 03:15:37</td>\n",
       "      <td>ebayUserAgent/eBayAndroid;6.179.0;Android;14;s...</td>\n",
       "      <td>5575319207</td>\n",
       "      <td>guyver13</td>\n",
       "      <td>226553867601852672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54241</th>\n",
       "      <td>172.225.240.192</td>\n",
       "      <td>2024-10-27 03:30:27</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 18_1 like M...</td>\n",
       "      <td>5575376664</td>\n",
       "      <td>winde_-129</td>\n",
       "      <td>226757201610955392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54242</th>\n",
       "      <td>172.226.114.83</td>\n",
       "      <td>2024-11-03 04:57:09</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 18_0_1 like...</td>\n",
       "      <td>5575791307</td>\n",
       "      <td>monika_pl</td>\n",
       "      <td>226837779948133120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CLNT_RMT_IP  ROI_CLICK_EVENT_TS  \\\n",
       "54238   172.226.114.69 2024-09-05 11:04:49   \n",
       "54239  208.115.224.233 2024-09-29 06:41:18   \n",
       "54240   138.199.29.213 2024-10-09 03:15:37   \n",
       "54241  172.225.240.192 2024-10-27 03:30:27   \n",
       "54242   172.226.114.83 2024-11-03 04:57:09   \n",
       "\n",
       "                                              BRWSR_NAME ams_pblshr_id  \\\n",
       "54238  ebayUserAgent/eBayIOS;6.174.0;iOS;17.6.1;Apple...    5575612316   \n",
       "54239  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...    5575532731   \n",
       "54240  ebayUserAgent/eBayAndroid;6.179.0;Android;14;s...    5575319207   \n",
       "54241  Mozilla/5.0 (iPhone; CPU iPhone OS 18_1 like M...    5575376664   \n",
       "54242  Mozilla/5.0 (iPhone; CPU iPhone OS 18_0_1 like...    5575791307   \n",
       "\n",
       "           buyer_id            click_id  \n",
       "54238         srw38  226172465646404352  \n",
       "54239  katzenklo_16  226442175813927936  \n",
       "54240      guyver13  226553867601852672  \n",
       "54241    winde_-129  226757201610955392  \n",
       "54242     monika_pl  226837779948133120  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full_dask_df = full_dask_df.drop(columns=['id', 'ams_trans_rsn_cd', 'is_vpn'])\n",
    "full_dask_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value count in 'click_id': 918884\n"
     ]
    }
   ],
   "source": [
    "unique_count = full_dask_df['click_id'].nunique().compute()\n",
    "\n",
    "# Display the result\n",
    "print(f\"Unique value count in 'click_id': {unique_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of rows : 1254243\n"
     ]
    }
   ],
   "source": [
    "print('no. of rows :', full_dask_df.shape[0].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test(300k rows) and train(100k rows) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 300000\n",
      "Testing set size: 100000\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Convert the Dask DataFrame to Pandas DataFrame\n",
    "full_df_pandas = full_dask_df.compute().reset_index(drop=True)\n",
    "\n",
    "# Sample 300k rows for the training set using Pandas\n",
    "train_df_pandas = full_df_pandas.sample(n=300000, random_state=42)\n",
    "\n",
    "# Remove the sampled rows for training set from the original DataFrame to get the remaining rows\n",
    "remaining_df_pandas = full_df_pandas[~full_df_pandas.index.isin(train_df_pandas.index)]\n",
    "\n",
    "# Sample 100k rows for the testing set from the remaining rows\n",
    "test_df_pandas = remaining_df_pandas.sample(n=100000, random_state=42)\n",
    "\n",
    "# Check the sizes of the sampled DataFrames\n",
    "train_size = train_df_pandas.shape[0]\n",
    "test_size = test_df_pandas.shape[0]\n",
    "\n",
    "print(f\"Training set size: {train_size}\")\n",
    "print(f\"Testing set size: {test_size}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_pandas.to_csv('../data/csv/train_set.csv', index=False)\n",
    "test_df_pandas.to_csv('../data/csv/test_set.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train dataset and implement preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/csv/train_set.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
