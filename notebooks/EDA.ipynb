{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n",
      "C:\\Users\\ramegupta\\AppData\\Local\\Temp\\ipykernel_15936\\3663271736.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_chunk = pd.read_sql_query(paginated_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     CLNT_RMT_IP  ROI_CLICK_EVENT_TS  \\\n",
      "0   1  77.111.247.168 2020-08-02 18:37:01   \n",
      "1   2   66.249.73.101 2020-08-21 03:36:38   \n",
      "2   3  77.111.247.129 2020-08-21 03:36:38   \n",
      "3   4   66.249.73.101 2020-08-21 03:36:33   \n",
      "4   5  77.111.247.129 2020-08-21 03:36:33   \n",
      "\n",
      "                                          BRWSR_NAME  ams_trans_rsn_cd  \\\n",
      "0  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "1  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "2  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "3  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "4  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...                 0   \n",
      "\n",
      "  ams_pblshr_id    buyer_id  is_vpn            click_id  \n",
      "0    5574672411   valen_949       1  209245484389035777  \n",
      "1    5574672411  morbanisaf       1  209453736892211586  \n",
      "2    5574672411  morbanisaf       1  209453736892211586  \n",
      "3    5574672411  morbanisaf       1  209453736892211586  \n",
      "4    5574672411  morbanisaf       1  209453736892211586  \n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import mysql.connector\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "# from scripts.db_utils import create_ebay_connection\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def create_ebay_connection():\n",
    "    \"\"\"Create connection to the hosted SQL Server database for IP addresses.\"\"\"\n",
    "    try:\n",
    "        connection = pyodbc.connect(\n",
    "            f\"DRIVER={{MySQL ODBC 9.1 Unicode Driver}};\"\n",
    "            f\"SERVER={os.getenv('EBAY_DB_HOST')};\"\n",
    "            f\"DATABASE={os.getenv('EBAY_DB_NAME')};\"\n",
    "            f\"UID={os.getenv('EBAY_DB_USER')};\"\n",
    "            f\"PWD={os.getenv('EBAY_DB_PASSWORD')}\"\n",
    "        )\n",
    "        return connection\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error connecting to hosted database: {e}\")\n",
    "        return None\n",
    "# Database connection parameters\n",
    "conn = create_ebay_connection()\n",
    "\n",
    "query = \"SELECT * FROM tbl_iptrace_user_activity where ams_trans_rsn_cd=0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_data_in_chunks(conn, query, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Fetch data from the database in chunks, then convert to Dask DataFrame.\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    while True:\n",
    "        # Modify the query to include pagination using LIMIT and OFFSET for chunks\n",
    "        paginated_query = f\"{query} LIMIT {chunk_size} OFFSET {offset}\"\n",
    "        \n",
    "        # Fetch data in chunks using pandas (it handles column and row alignment internally)\n",
    "        df_chunk = pd.read_sql_query(paginated_query, conn)\n",
    "        \n",
    "        if df_chunk.empty:\n",
    "            break\n",
    "        \n",
    "        # Convert to Dask DataFrame\n",
    "        dask_df = dd.from_pandas(df_chunk, npartitions=4)\n",
    "        \n",
    "        yield dask_df\n",
    "        \n",
    "        offset += chunk_size\n",
    "\n",
    "\n",
    "dask_chunks = []\n",
    "\n",
    "# Fetch chunks and store them in the list\n",
    "for dask_df_chunk in fetch_data_in_chunks(conn, query, chunk_size=100000):\n",
    "    dask_chunks.append(dask_df_chunk)\n",
    "\n",
    "# Concatenate all chunks into a single Dask DataFrame\n",
    "full_dask_df = dd.concat(dask_chunks)\n",
    "\n",
    "# Now you can perform operations on full_dask_df\n",
    "# result = full_dask_df.groupby('some_column').agg({'another_column': 'mean'})\n",
    "\n",
    "# Compute the result\n",
    "# computed_result = result.compute()\n",
    "\n",
    "# Show the result\n",
    "print(full_dask_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1254243, Columns: 9\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the DataFrame (number of rows and columns)\n",
    "num_rows, num_columns = full_dask_df.shape[0].compute(), full_dask_df.shape[1]\n",
    "\n",
    "print(f\"Rows: {num_rows}, Columns: {num_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
